{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taken from https://colab.research.google.com/drive/1974D-qP17fd5mLxy6QZv-ic4yxlPJp-G?usp=sharing#scrollTo=lhnJkrYLOvcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup TPU\n",
    "import jax.tools.colab_tpu\n",
    "#jax.tools.colab_tpu.setup_tpu()\n",
    "\n",
    "# Imports\n",
    "import chex\n",
    "import jax\n",
    "import haiku as hk\n",
    "from jax import lax\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import rlax\n",
    "import timeit\n",
    "jax.devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeIt():\n",
    "\n",
    "    def __init__(self, tag, frames=None):\n",
    "        self.tag = tag\n",
    "        self.frames = frames\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = timeit.default_timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.elapsed_secs = timeit.default_timer() - self.start\n",
    "        msg = self.tag + (': Elapsed time=%.2fs' % self.elapsed_secs)\n",
    "        if self.frames:\n",
    "            msg += ', FPS=%.2e' % (self.frames / self.elapsed_secs)\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catch:\n",
    "  \"\"\"A JAX implementation of the Catch gridworld.\"\"\"\n",
    "\n",
    "  def __init__(self, rows: int = 10, columns: int = 5):\n",
    "    self._rows = rows\n",
    "    self._columns = columns\n",
    "    self.num_actions = 3\n",
    "\n",
    "  def initial_state(self, rng):\n",
    "    ball_y = 0\n",
    "    ball_x = random.randint(rng, (), 0, self._columns)\n",
    "    paddle_y = self._rows - 1\n",
    "    paddle_x = self._columns // 2\n",
    "    return lax.stop_gradient(jnp.array((ball_y, ball_x, paddle_y, paddle_x), dtype=jnp.int32))\n",
    "\n",
    "  def step(self, rng, state, action):\n",
    "    is_terminal = self.is_terminal(state)\n",
    "    paddle_x = jnp.clip(state[3] + action - 1, 0, self._columns - 1)\n",
    "    state = jnp.array([state[0] + 1, state[1], state[2], paddle_x])\n",
    "    state = lax.select(is_terminal, self.initial_state(rng), state)\n",
    "    return lax.stop_gradient(state)\n",
    "\n",
    "  def observation(self, state):\n",
    "    return (self.render(state), self.reward(state),\n",
    "            self.discount(state), self.is_terminal(state))\n",
    "\n",
    "  def render(self, state):\n",
    "    def f(y, x):\n",
    "      return lax.select(\n",
    "          jnp.bitwise_or(\n",
    "              jnp.bitwise_and(y == state[0], x == state[1]),\n",
    "              jnp.bitwise_and(y == state[2], x == state[3])), 1., 0.)\n",
    "    y_board = jnp.repeat(jnp.arange(self._rows), self._columns)\n",
    "    x_board = jnp.tile(jnp.arange(self._columns), self._rows)\n",
    "    return jax.vmap(f)(y_board, x_board).reshape((self._rows, self._columns, 1))\n",
    "\n",
    "  def reward(self, state):\n",
    "    return lax.select(\n",
    "        self.is_terminal(state), lax.select(state[1] == state[3], 1., -1.), 0.)\n",
    "\n",
    "  def discount(self, state):\n",
    "    return lax.select(self.is_terminal(state), 0., 1.)\n",
    "\n",
    "  def is_terminal(self, state):\n",
    "    return state[0] == self._rows - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chex.dataclass(frozen=True)\n",
    "class TimeStep:\n",
    "    q_values: chex.Array\n",
    "    action: chex.Array\n",
    "    discount: chex.Array\n",
    "    reward: chex.Array\n",
    "\n",
    "def get_network_fn(num_outputs: int):\n",
    "    \"\"\"Define a fully connected multi-layer haiku network.\"\"\"\n",
    "    def network_fn(obs: chex.Array) -> chex.Array:\n",
    "        return hk.Sequential([  # flatten, hidden layer, relu, output layer.\n",
    "            hk.Flatten(), hk.Linear(256), jax.nn.relu, hk.Linear(num_outputs)])(obs)\n",
    "    return hk.without_apply_rng(hk.transform(network_fn))\n",
    "\n",
    "def get_learner_fn(\n",
    "    env, forward_pass, opt_update, rollout_len, agent_discount,\n",
    "    lambda_, iterations):\n",
    "    \"\"\"Define the minimal unit of computation in Anakin.\"\"\"\n",
    "\n",
    "    def loss_fn(params, outer_rng, env_state):\n",
    "        \"\"\"Compute the loss on a single trajectory.\"\"\"\n",
    "\n",
    "        def step_fn(env_state, rng):\n",
    "            obs, reward, discount, is_terminal = env.observation(env_state)\n",
    "            q_values = forward_pass(params, obs[None,])[0]  # forward pass.\n",
    "            action = jnp.argmax(q_values)  # greedy policy.\n",
    "            env_state = env.step(rng, env_state, action)  # step environment.\n",
    "            return env_state, TimeStep(  # return env state and transition data.\n",
    "              q_values=q_values, action=action, discount=discount, reward=reward)\n",
    "\n",
    "        step_rngs = random.split(outer_rng, rollout_len)\n",
    "        env_state, rollout = lax.scan(step_fn, env_state, step_rngs)  # trajectory.\n",
    "        qa_tm1 = rlax.batched_index(rollout.q_values[:-1], rollout.action[:-1])\n",
    "        td_error = rlax.td_lambda(  # compute multi-step temporal diff error.\n",
    "            v_tm1=qa_tm1,  # predictions.\n",
    "            r_t=rollout.reward[1:],  # rewards.\n",
    "            discount_t=agent_discount * rollout.discount[1:],  # discount.\n",
    "            v_t=jnp.max(rollout.q_values[1:], axis=-1),  # bootstrap values.\n",
    "            lambda_=lambda_)  # mixing hyper-parameter lambda.\n",
    "        return jnp.mean(td_error**2), env_state\n",
    "\n",
    "    def update_fn(params, opt_state, rng, env_state):\n",
    "        \"\"\"Compute a gradient update from a single trajectory.\"\"\"\n",
    "        rng, loss_rng = random.split(rng)\n",
    "        grads, new_env_state = jax.grad(  # compute gradient on a single trajectory.\n",
    "            loss_fn, has_aux=True)(params, loss_rng, env_state)\n",
    "        grads = lax.pmean(grads, axis_name='j')  # reduce mean across cores.\n",
    "        grads = lax.pmean(grads, axis_name='i')  # reduce mean across batch.\n",
    "        updates, new_opt_state = opt_update(grads, opt_state)  # transform grads.\n",
    "        new_params = optax.apply_updates(params, updates)  # update parameters.\n",
    "        return new_params, new_opt_state, rng, new_env_state\n",
    "\n",
    "    def learner_fn(params, opt_state, rngs, env_states):\n",
    "        \"\"\"Vectorise and repeat the update.\"\"\"\n",
    "        batched_update_fn = jax.vmap(update_fn, axis_name='j')  # vectorize across batch.\n",
    "        def iterate_fn(_, val):  # repeat many times to avoid going back to Python.\n",
    "            params, opt_state, rngs, env_states = val\n",
    "            return batched_update_fn(params, opt_state, rngs, env_states)\n",
    "        return lax.fori_loop(0, iterations, iterate_fn, (\n",
    "            params, opt_state, rngs, env_states))\n",
    "\n",
    "    return learner_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(env, batch_size, rollout_len, step_size, iterations, seed):\n",
    "    \"\"\"Runs experiment.\"\"\"\n",
    "    cores_count = len(jax.devices())  # get available TPU cores.\n",
    "    network = get_network_fn(env.num_actions)  # define network.\n",
    "    optim = optax.adam(step_size)  # define optimiser.\n",
    "\n",
    "    rng, rng_e, rng_p = random.split(random.PRNGKey(seed), num=3)  # prng keys.\n",
    "    dummy_obs = env.render(env.initial_state(rng_e))[None,]  # dummy for net init.\n",
    "    params = network.init(rng_p, dummy_obs)  # initialise params.\n",
    "    opt_state = optim.init(params)  # initialise optimiser stats.\n",
    "\n",
    "    learn = get_learner_fn(  # get batched iterated update.\n",
    "      env, network.apply, optim.update, rollout_len=rollout_len,\n",
    "      agent_discount=1, lambda_=0.99, iterations=iterations)\n",
    "    learn = jax.pmap(learn, axis_name='i')  # replicate over multiple cores.\n",
    "\n",
    "    broadcast = lambda x: jnp.broadcast_to(x, (cores_count, batch_size) + x.shape)\n",
    "    params = jax.tree_map(broadcast, params)  # broadcast to cores and batch.\n",
    "    opt_state = jax.tree_map(broadcast, opt_state)  # broadcast to cores and batch\n",
    "\n",
    "    rng, *env_rngs = jax.random.split(rng, cores_count * batch_size + 1)\n",
    "    env_states = jax.vmap(env.initial_state)(jnp.stack(env_rngs))  # init envs.\n",
    "    rng, *step_rngs = jax.random.split(rng, cores_count * batch_size + 1)\n",
    "\n",
    "    reshape = lambda x: x.reshape((cores_count, batch_size) + x.shape[1:])\n",
    "    step_rngs = reshape(jnp.stack(step_rngs))  # add dimension to pmap over.\n",
    "    env_states = reshape(env_states)  # add dimension to pmap over.\n",
    "\n",
    "    with TimeIt(tag='COMPILATION'):\n",
    "        learn(params, opt_state, step_rngs, env_states)  # compiles\n",
    "\n",
    "    num_frames = cores_count * iterations * rollout_len * batch_size\n",
    "    with TimeIt(tag='EXECUTION', frames=num_frames):\n",
    "        params, opt_state, step_rngs, env_states = learn(  # runs compiled fn\n",
    "            params, opt_state, step_rngs, env_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 cores.\n",
      "COMPILATION: Elapsed time=8.86s\n",
      "EXECUTION: Elapsed time=0.01s, FPS=3.84e+07\n"
     ]
    }
   ],
   "source": [
    "print('Running on', len(jax.devices()), 'cores.', flush=True)  # !expected 8!\n",
    "run_experiment(Catch(), 128, 16, 1e-4, 100, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ma-vision)",
   "language": "python",
   "name": "ma-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
